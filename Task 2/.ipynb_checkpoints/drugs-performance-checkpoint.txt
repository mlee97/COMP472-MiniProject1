------------------------------------Step 7------------------------------------

(a)
Model name: Gaussian Naive Bayes Classifier

(b) Confusion matrix:

[[ 0  1  1  1  0]
 [ 0  0  0  2  0]
 [ 2  0  2  2  0]
 [ 3  1  1  2  8]
 [ 7  2  2  3 10]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       0.75      1.00      0.86         9
       drugB       1.00      1.00      1.00         4
       drugC       0.33      1.00      0.50         2
       drugX       1.00      1.00      1.00        10
       drugY       1.00      0.72      0.84        25

    accuracy                           0.86        50
   macro avg       0.82      0.94      0.84        50
weighted avg       0.93      0.86      0.87        50


****************************************************************

(a)
Model name: Decision Tree

(b) Confusion matrix:

[[ 0  1  0  1  1]
 [ 0  0  0  2  0]
 [ 2  0  1  2  1]
 [ 2  1  0  2 10]
 [ 5  2  1  3 13]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       1.00      1.00      1.00         9
       drugB       1.00      1.00      1.00         4
       drugC       1.00      1.00      1.00         2
       drugX       1.00      1.00      1.00        10
       drugY       1.00      1.00      1.00        25

    accuracy                           1.00        50
   macro avg       1.00      1.00      1.00        50
weighted avg       1.00      1.00      1.00        50


****************************************************************

(a)
Model name: A better performing Decision Tree

Changed hyper-parameters values: 
- criterion (gini or entropy)
- max_depth (3, 5)
- min_samples_split (2, 6, 10)

Best hyper-parameters:{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}

(b) Confusion matrix:

[[ 0  1  0  1  1]
 [ 0  0  0  2  0]
 [ 2  0  1  2  1]
 [ 2  1  0  2 10]
 [ 5  2  1  3 13]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       1.00      1.00      1.00         9
       drugB       1.00      1.00      1.00         4
       drugC       1.00      1.00      1.00         2
       drugX       1.00      1.00      1.00        10
       drugY       1.00      1.00      1.00        25

    accuracy                           1.00        50
   macro avg       1.00      1.00      1.00        50
weighted avg       1.00      1.00      1.00        50


****************************************************************

(a)
Model name: Perceptron

(b) Confusion matrix:

[[ 0  0  0  2  1]
 [ 1  0  0  1  0]
 [ 0  0  0  6  0]
 [ 0  0  0  7  8]
 [ 0  0  0 12 12]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       0.00      0.00      0.00         9
       drugB       0.00      0.00      0.00         4
       drugC       0.00      0.00      0.00         2
       drugX       0.32      0.90      0.47        10
       drugY       1.00      0.84      0.91        25

    accuracy                           0.60        50
   macro avg       0.26      0.35      0.28        50
weighted avg       0.56      0.60      0.55        50


****************************************************************

(a)
Model name: Multi-Layered Perceptron

(b) Confusion matrix:

[[ 0  0  0  2  1]
 [ 0  0  0  1  1]
 [ 0  0  0  2  4]
 [ 0  0  0  2 13]
 [ 0  0  0  8 16]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       0.00      0.00      0.00         9
       drugB       0.00      0.00      0.00         4
       drugC       0.00      0.00      0.00         2
       drugX       0.47      0.70      0.56        10
       drugY       0.71      1.00      0.83        25

    accuracy                           0.64        50
   macro avg       0.24      0.34      0.28        50
weighted avg       0.45      0.64      0.53        50


****************************************************************

(a)
Model name: A better performing Multi-Layered Perceptron

Changed hyper-parameters values: 
- activation function (sigmoid, tanh, relu and identity)
- 2 network architectures(2 hidden layers with 30+50 nodes and 3 hidden layers with 10 + 10 + 10)
- solver (Adam and stochastic gradient descent)

Best hyper-parameters:{'activation': 'tanh', 'hidden_layer_sizes': [30, 50], 'solver': 'adam'}

(b) Confusion matrix:

[[ 0  0  0  2  1]
 [ 0  0  0  1  1]
 [ 0  0  0  2  4]
 [ 0  0  0  2 13]
 [ 0  0  0  8 16]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       0.00      0.00      0.00         9
       drugB       0.00      0.00      0.00         4
       drugC       0.00      0.00      0.00         2
       drugX       0.47      0.70      0.56        10
       drugY       0.71      1.00      0.83        25

    accuracy                           0.64        50
   macro avg       0.24      0.34      0.28        50
weighted avg       0.45      0.64      0.53        50


------------------------------------Step 8------------------------------------

1. Redo the Gaussian Naive Bayes Classifier 10 times

Average accuracy: 0.86
Macro-average f1: 0.8388704318936877
Weighted-average f1: 0.8728903654485048

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the macro-average F1: 0.0

****************************************************************

2. Redo the Decision Tree Classifier 10 times

Average accuracy: 1.0
Macro-average f1: 1.0
Weighted-average f1: 1.0

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the macro-average F1: 0.0

****************************************************************

3. Redo the Top Decision Tree 10 times

Average accuracy: 1.0
Macro-average f1: 1.0
Weighted-average f1: 1.0

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the macro-average F1: 0.0

****************************************************************

4. Redo the Perceptron 10 times

Average accuracy: 0.6
Macro-average f1: 0.2773455377574371
Weighted-average f1: 0.551258581235698

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the macro-average F1: 0.0

****************************************************************

5. Redo the Multi-Layered Perceptron Classifier 10 times

Average accuracy: 0.64
Macro-average f1: 0.2778186162604631
Weighted-average f1: 0.5303756004802176

Standard deviation for the accuracy: 1.1102230246251565e-16
Standard deviation of the macro-average F1: 0.0009000862966147428
Standard deviation of the macro-average F1: 0.0019495354595539043

****************************************************************

6. Redo the Top Multi-Layered Perceptron Classifier 10 times