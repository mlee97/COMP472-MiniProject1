------------------------------------Step 7------------------------------------

(a)
Model name: Gaussian Naive Bayes Classifier

(b) Confusion matrix:

[[ 0  0  0  2  1]
 [ 1  0  0  0  1]
 [ 1  1  1  1  2]
 [ 4  0  3  3  5]
 [ 3  0  4  5 12]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       0.56      1.00      0.71         5
       drugB       1.00      1.00      1.00         1
       drugC       0.88      1.00      0.93         7
       drugX       1.00      0.92      0.96        12
       drugY       0.95      0.80      0.87        25

    accuracy                           0.88        50
   macro avg       0.88      0.94      0.89        50
weighted avg       0.91      0.88      0.89        50


****************************************************************

(a)
Model name: Decision Tree

(b) Confusion matrix:

[[ 0  0  0  2  1]
 [ 1  0  0  0  1]
 [ 0  1  1  1  3]
 [ 3  0  3  3  6]
 [ 1  0  3  6 14]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       1.00      1.00      1.00         5
       drugB       1.00      1.00      1.00         1
       drugC       1.00      1.00      1.00         7
       drugX       1.00      1.00      1.00        12
       drugY       1.00      1.00      1.00        25

    accuracy                           1.00        50
   macro avg       1.00      1.00      1.00        50
weighted avg       1.00      1.00      1.00        50


****************************************************************

(a)
Model name: A better performing Decision Tree

Changed hyper-parameters values: 
- criterion (gini or entropy)
- max_depth (3, 5)
- min_samples_split (2, 6, 10)

Best hyper-parameters:{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}

(b) Confusion matrix:

[[ 0  0  0  2  1]
 [ 1  0  0  0  1]
 [ 0  1  1  1  3]
 [ 3  0  3  3  6]
 [ 1  0  3  6 14]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       1.00      1.00      1.00         5
       drugB       1.00      1.00      1.00         1
       drugC       1.00      1.00      1.00         7
       drugX       1.00      1.00      1.00        12
       drugY       1.00      1.00      1.00        25

    accuracy                           1.00        50
   macro avg       1.00      1.00      1.00        50
weighted avg       1.00      1.00      1.00        50


****************************************************************

(a)
Model name: Perceptron

(b) Confusion matrix:

[[ 0  0  0  0  3]
 [ 0  1  0  0  1]
 [ 0  0  0  0  6]
 [ 0  1  0  1 13]
 [ 0  2  0  1 21]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       0.00      0.00      0.00         5
       drugB       0.00      0.00      0.00         1
       drugC       0.00      0.00      0.00         7
       drugX       0.50      0.08      0.14        12
       drugY       0.57      1.00      0.72        25

    accuracy                           0.52        50
   macro avg       0.21      0.22      0.17        50
weighted avg       0.40      0.52      0.40        50


****************************************************************

(a)
Model name: Multi-Layered Perceptron

(b) Confusion matrix:

[[ 0  0  0  0  3]
 [ 0  0  0  1  1]
 [ 0  0  0  1  5]
 [ 0  0  0  3 12]
 [ 0  0  0  6 18]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       0.00      0.00      0.00         5
       drugB       0.00      0.00      0.00         1
       drugC       0.00      0.00      0.00         7
       drugX       0.55      0.50      0.52        12
       drugY       0.64      1.00      0.78        25

    accuracy                           0.62        50
   macro avg       0.24      0.30      0.26        50
weighted avg       0.45      0.62      0.52        50


****************************************************************

(a)
Model name: A better performing Multi-Layered Perceptron

Changed hyper-parameters values: 
- activation function (sigmoid, tanh, relu and identity)
- 2 network architectures(2 hidden layers with 30+50 nodes and 3 hidden layers with 10 + 10 + 10)
- solver (Adam and stochastic gradient descent)

Best hyper-parameters:{'activation': 'tanh', 'hidden_layer_sizes': [30, 50], 'solver': 'adam'}

(b) Confusion matrix:

[[ 0  0  0  0  3]
 [ 0  0  0  1  1]
 [ 0  0  0  1  5]
 [ 0  0  0  3 12]
 [ 0  0  0  6 18]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       0.00      0.00      0.00         5
       drugB       0.00      0.00      0.00         1
       drugC       0.00      0.00      0.00         7
       drugX       0.55      0.50      0.52        12
       drugY       0.64      1.00      0.78        25

    accuracy                           0.62        50
   macro avg       0.24      0.30      0.26        50
weighted avg       0.45      0.62      0.52        50


------------------------------------Step 8------------------------------------

1. Redo the Gaussian Naive Bayes Classifier 10 times

Average accuracy: 0.88
Macro-average f1: 0.8947412008281574
Weighted-average f1: 0.8864430641821945

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the weighted-average F1: 0.0

****************************************************************

2. Redo the Decision Tree Classifier 10 times

Average accuracy: 1.0
Macro-average f1: 1.0
Weighted-average f1: 1.0

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the weighted-average F1: 0.0

****************************************************************

3. Redo the Top Decision Tree 10 times

Average accuracy: 1.0
Macro-average f1: 1.0
Weighted-average f1: 1.0

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the weighted-average F1: 0.0

****************************************************************

4. Redo the Perceptron 10 times

Average accuracy: 0.52
Macro-average f1: 0.17349896480331264
Weighted-average f1: 0.39660455486542445

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the weighted-average F1: 0.0

****************************************************************

5. Redo the Multi-Layered Perceptron Classifier 10 times

Average accuracy: 0.62
Macro-average f1: 0.26059782608695653
Weighted-average f1: 0.5158423913043478

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the weighted-average F1: 0.0

****************************************************************

6. Redo the Top Multi-Layered Perceptron Classifier 10 times