{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15c38833-f901-4192-a1cf-e68ce0464c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, f1_score, accuracy_score\n",
    "import statistics\n",
    "import warnings\n",
    "\n",
    "#Make a list of classes\n",
    "classes = ['DrugA', 'DrugB', 'DrugC', 'DrugX', 'DrugY']\n",
    "#Make an empty list to store the amount of instances per class\n",
    "numInstancesPerClass = []\n",
    "\n",
    "#-------------Step 2: Load the dataset-------------#\n",
    "\n",
    "#Load the dataset\n",
    "dataframe = pd.read_csv('drug200.csv')  \n",
    "\n",
    "#-------------Step 3: Plot Instances-------------#\n",
    "\n",
    "#Count Number of Instances of DrugA\n",
    "numDrugA = (dataframe['Drug']=='drugA').sum()\n",
    "numInstancesPerClass.append(numDrugA)\n",
    "\n",
    "#Count Number of Instances of DrugB\n",
    "numDrugB = (dataframe['Drug']=='drugB').sum()\n",
    "numInstancesPerClass.append(numDrugB)\n",
    "\n",
    "#Count Number of Instances of DrugC\n",
    "numDrugC = (dataframe['Drug']=='drugC').sum()\n",
    "numInstancesPerClass.append(numDrugC)\n",
    "\n",
    "#Count Number of Instances of DrugX\n",
    "numDrugX = (dataframe['Drug']=='drugX').sum()\n",
    "numInstancesPerClass.append(numDrugX)\n",
    "\n",
    "#Count Number of Instances of DrugY\n",
    "numDrugY = (dataframe['Drug']=='drugY').sum()\n",
    "numInstancesPerClass.append(numDrugY)\n",
    "\n",
    "#Plot bar graph of the number of instances per class.\n",
    "plt.bar(classes, numInstancesPerClass)\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('instances per class')\n",
    "\n",
    "#Save graph to a PDF file\n",
    "plt.savefig(\"drug-distribution.pdf\")\n",
    "\n",
    "#-------------Step 4: Convert ordinal and nominal features in numerical format-------------#\n",
    "#pd.Categorical(data['BP'], ordered = True, categories=['LOW', 'NORMAL', 'HIGH'])\n",
    "#pd.Categorical(data['Cholesterol'], ordered = True, categories=['LOW', 'NORMAL', 'HIGH'])\n",
    "\n",
    "dataframe['BP'].replace(to_replace=['LOW', 'NORMAL', 'HIGH'], value=[1, 2, 3], inplace=True)\n",
    "dataframe['Cholesterol'].replace(to_replace=['LOW', 'NORMAL', 'HIGH'], value=[1, 2, 3], inplace=True)\n",
    "dataframe = pd.get_dummies(dataframe, columns=['Sex'])\n",
    "\n",
    "# print(\"---------Dataframe----------\")\n",
    "# print(dataframe)\n",
    "\n",
    "#-------------Step 5: Split the dataset-------------#\n",
    "\n",
    "#specify attributes\n",
    "X = dataframe.drop('Drug', axis=1)\n",
    "#specify output\n",
    "y = dataframe.Drug\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "#-------------Step 6: Run 6 different classifiers-------------#\n",
    "\n",
    "#-(a)NB-#\n",
    "nbClf = GaussianNB()\n",
    "nbClf.fit(X_train, y_train)\n",
    "\n",
    "# print(\"---------6 a)----------\")\n",
    "nb_predictions = nbClf.predict(X_test)\n",
    "# print(nb_predictions)\n",
    "\n",
    "#-(b)Base_DT-#\n",
    "dtClf = DecisionTreeClassifier()\n",
    "dtClf.fit(X_train, y_train)\n",
    "\n",
    "# print(\"---------6 b)----------\")\n",
    "dtClf_predictions = dtClf.predict(X_test)\n",
    "# print(dtClf_predictions)\n",
    "\n",
    "#-(c)Top_DT-#\n",
    "# Defining the hyper-parameters we will experiment with\n",
    "top_DT_param_grid = {'criterion': ['gini', 'entropy'],\n",
    "                     'max_depth': [3, 5],\n",
    "                     'min_samples_split': [2, 6, 10]}\n",
    " \n",
    "topDtClf = GridSearchCV(DecisionTreeClassifier(), top_DT_param_grid)\n",
    "\n",
    "# Fit the model for grid search\n",
    "topDtClf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the output\n",
    "# print(\"---------6 c)----------\")\n",
    "topDtClf_predictions = topDtClf.predict(X_test)\n",
    "# print(topDtClf_predictions)\n",
    "\n",
    "# Print the best hyperparameters found by the gridsearch\n",
    "# print(\"Best top-DT hyperparameters:\")\n",
    "# print(topDtClf.best_params_)\n",
    "\n",
    "\n",
    "#-(d)Perceptron-#\n",
    "perClf = Perceptron()\n",
    "perClf.fit(X_train, y_train)\n",
    "\n",
    "# print(\"---------6 d)----------\")\n",
    "perClf_predictions = perClf.predict(X_test)\n",
    "# print(perClf_predictions)\n",
    "\n",
    "# Ignore convergence warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#-(e)Base-MLP-#\n",
    "mlpClf = MLPClassifier(hidden_layer_sizes = (100, ), activation = 'logistic', solver = 'sgd')\n",
    "mlpClf.fit(X_train, y_train)\n",
    "\n",
    "# print(\"---------6 e)----------\")\n",
    "mlpClf_predictions = mlpClf.predict(X_test)\n",
    "# print(mlpClf_predictions)\n",
    "\n",
    "\n",
    "#-(f)Top-MLP-#\n",
    "# Defining the hyper-parameters we will experiment with\n",
    "top_MLP_param_grid = {'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "                      'hidden_layer_sizes': [[30, 50], [10, 10, 10]],\n",
    "                      'solver': ['adam', 'sgd']}\n",
    "\n",
    "topMlpClf = GridSearchCV(MLPClassifier(), top_MLP_param_grid)\n",
    "\n",
    "# Fit the model for grid search\n",
    "topMlpClf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the output\n",
    "# print(\"---------6 f)----------\")\n",
    "topMlpClf_predictions = topMlpClf.predict(X_test)\n",
    "# print(topMlpClf_predictions)\n",
    "\n",
    "# Print the best hyperparameters found by the gridsearch\n",
    "# print(\"Best top-MLP hyperparameters:\")\n",
    "# print(topMlpClf.best_params_)\n",
    "\n",
    "#-------------Step 7: Append information in a file called 'drugs-performance.txt'-------------#\n",
    "\n",
    "#-------------------------------------------1.NB classifier-----------------------------------#\n",
    "#-------------(a)Append a clear seperator-------------#\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"------------------------------------Step 7------------------------------------\")\n",
    "    drug_performance.write(\"\\n\\n(a)\")\n",
    "    drug_performance.write(\"\\nModel name: Gaussian Naive Bayes Classifier\")\n",
    "\n",
    "#--------------(b)Confusion matrix-------------#\n",
    "# Getting the first 50 rows of the correct drug output\n",
    "true_classes = y.head(50)\n",
    "\n",
    "# Computing the confusion matrix and converting it to a string\n",
    "nb_confusion_matrix = np.array2string(confusion_matrix(true_classes, nb_predictions))\n",
    "\n",
    "# Appending the confusion matrix to .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n(b) Confusion matrix:\\n\\n\")\n",
    "    drug_performance.write(nb_confusion_matrix)\n",
    "    \n",
    "#-------------(c) Precision, recall, and F1-measure for each class + d) accuracy, macro-average F1 and weighted-average F1 of the model-------------#\n",
    "\n",
    "nb_classification_report = classification_report(y_test, nb_predictions)\n",
    "\n",
    "# Appending the classification report to .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n(c) Precision, recall, and F1-measure for each class AND \\n(d) Accuracy, macro-average F1 and weighted-average F1 of the model:\\n\\n\")\n",
    "    drug_performance.write(nb_classification_report)\n",
    "\n",
    "\n",
    "#-------------------------------------------2.Base-DT classifier-----------------------------------#\n",
    "\n",
    "#-------------(a)Append a clear seperator-------------#\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n****************************************************************\")\n",
    "    drug_performance.write(\"\\n\\n(a)\")\n",
    "    drug_performance.write(\"\\nModel name: Decision Tree\")\n",
    "    \n",
    "#--------------(b)Confusion matrix-------------#\n",
    "\n",
    "# Computing the confusion matrix and converting it to a string\n",
    "base_dt_confusion_matrix = np.array2string(confusion_matrix(true_classes, dtClf_predictions))\n",
    "\n",
    "# Appending the confusion matrix to .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n(b) Confusion matrix:\\n\\n\")\n",
    "    drug_performance.write(base_dt_confusion_matrix)\n",
    "\n",
    "#-------------(c) Precision, recall, and F1-measure for each class + d) accuracy, macro-average F1 and weighted-average F1 of the model-------------#\n",
    "\n",
    "base_dt_classification_report = classification_report(y_test, dtClf_predictions)\n",
    "\n",
    "# Appending the classification report to .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n(c) Precision, recall, and F1-measure for each class AND \\n(d) Accuracy, macro-average F1 and weighted-average F1 of the model:\\n\\n\")\n",
    "    drug_performance.write(base_dt_classification_report)\n",
    "    \n",
    "\n",
    "#-------------------------------------------3.Top-DT classifier-----------------------------------#\n",
    "\n",
    "#-------------(a)Append a clear seperator-------------#\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n****************************************************************\")\n",
    "    drug_performance.write(\"\\n\\n(a)\")\n",
    "    drug_performance.write(\"\\nModel name: A better performing Decision Tree\")        \n",
    "    drug_performance.write(\"\\n\\nChanged hyper-parameters values: \\n- criterion (gini or entropy)\\n- max_depth (3, 5)\\n- min_samples_split (2, 6, 10)\")\n",
    "    drug_performance.write(\"\\n\\nBest hyper-parameters:\")         \n",
    "    drug_performance.write(str(topDtClf.best_params_)) \n",
    "    \n",
    "#--------------(b)Confusion matrix-------------#\n",
    "\n",
    "# Computing the confusion matrix and converting it to a string\n",
    "top_dt_confusion_matrix = np.array2string(confusion_matrix(true_classes, topDtClf_predictions))\n",
    "\n",
    "# Appending the confusion matrix to .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n(b) Confusion matrix:\\n\\n\")\n",
    "    drug_performance.write(top_dt_confusion_matrix)\n",
    "\n",
    "#-------------(c) Precision, recall, and F1-measure for each class + d) accuracy, macro-average F1 and weighted-average F1 of the model-------------#\n",
    "\n",
    "top_dt_classification_report = classification_report(y_test, topDtClf_predictions)\n",
    "\n",
    "# Appending the classification report to .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n(c) Precision, recall, and F1-measure for each class AND \\n(d) Accuracy, macro-average F1 and weighted-average F1 of the model:\\n\\n\")\n",
    "    drug_performance.write(top_dt_classification_report)\n",
    "    \n",
    "    \n",
    "#-------------------------------------------4.Perceptron-----------------------------------#\n",
    "\n",
    "#-------------(a)Append a clear seperator-------------#\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n****************************************************************\")\n",
    "    drug_performance.write(\"\\n\\n(a)\")\n",
    "    drug_performance.write(\"\\nModel name: Perceptron\")        \n",
    "    \n",
    "#--------------(b)Confusion matrix-------------#\n",
    "\n",
    "# Computing the confusion matrix and converting it to a string\n",
    "perceptron_confusion_matrix = np.array2string(confusion_matrix(true_classes, perClf_predictions))\n",
    "\n",
    "# Appending the confusion matrix to .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n(b) Confusion matrix:\\n\\n\")\n",
    "    drug_performance.write(perceptron_confusion_matrix)\n",
    "\n",
    "#-------------(c) Precision, recall, and F1-measure for each class + d) accuracy, macro-average F1 and weighted-average F1 of the model-------------#\n",
    "\n",
    "perceptron_classification_report = classification_report(y_test, perClf_predictions)\n",
    "\n",
    "# Appending the classification report to .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n(c) Precision, recall, and F1-measure for each class AND \\n(d) Accuracy, macro-average F1 and weighted-average F1 of the model:\\n\\n\")\n",
    "    drug_performance.write(perceptron_classification_report)   \n",
    "    \n",
    "    \n",
    "#-------------------------------------------5.Base-MLP classifier-----------------------------------#\n",
    "\n",
    "#-------------(a)Append a clear seperator-------------#\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n****************************************************************\")\n",
    "    drug_performance.write(\"\\n\\n(a)\")\n",
    "    drug_performance.write(\"\\nModel name: Multi-Layered Perceptron\")        \n",
    "    \n",
    "#--------------(b)Confusion matrix-------------#\n",
    "\n",
    "# Computing the confusion matrix and converting it to a string\n",
    "MLP_confusion_matrix = np.array2string(confusion_matrix(true_classes, mlpClf_predictions))\n",
    "\n",
    "# Appending the confusion matrix to .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n(b) Confusion matrix:\\n\\n\")\n",
    "    drug_performance.write(MLP_confusion_matrix)\n",
    "\n",
    "#-------------(c) Precision, recall, and F1-measure for each class + d) accuracy, macro-average F1 and weighted-average F1 of the model-------------#\n",
    "\n",
    "MLP_classification_report = classification_report(y_test, mlpClf_predictions)\n",
    "\n",
    "# Appending the classification report to .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n(c) Precision, recall, and F1-measure for each class AND \\n(d) Accuracy, macro-average F1 and weighted-average F1 of the model:\\n\\n\")\n",
    "    drug_performance.write(MLP_classification_report)   \n",
    "\n",
    "#-------------------------------------------6.Top-MLP classifier-----------------------------------#\n",
    "\n",
    "#-------------(a)Append a clear seperator-------------#\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n****************************************************************\")\n",
    "    drug_performance.write(\"\\n\\n(a)\")\n",
    "    drug_performance.write(\"\\nModel name: A better performing Multi-Layered Perceptron\")        \n",
    "    drug_performance.write(\"\\n\\nChanged hyper-parameters values: \\n- activation function (sigmoid, tanh, relu and identity)\\n- 2 network architectures(2 hidden layers with 30+50 nodes and 3 hidden layers with 10 + 10 + 10)\\n- solver (Adam and stochastic gradient descent)\")\n",
    "    drug_performance.write(\"\\n\\nBest hyper-parameters:\")         \n",
    "    drug_performance.write(str(topMlpClf.best_params_)) \n",
    "    \n",
    "#--------------(b)Confusion matrix-------------#\n",
    "\n",
    "# Computing the confusion matrix and converting it to a string\n",
    "top_mlp_confusion_matrix = np.array2string(confusion_matrix(true_classes, mlpClf_predictions))\n",
    "\n",
    "# Appending the confusion matrix to .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n(b) Confusion matrix:\\n\\n\")\n",
    "    drug_performance.write(top_mlp_confusion_matrix)\n",
    "\n",
    "#-------------(c) Precision, recall, and F1-measure for each class + d) accuracy, macro-average F1 and weighted-average F1 of the model-------------#\n",
    "\n",
    "top_mlp_classification_report = classification_report(y_test, mlpClf_predictions)\n",
    "\n",
    "# Appending the classification report to .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n(c) Precision, recall, and F1-measure for each class AND \\n(d) Accuracy, macro-average F1 and weighted-average F1 of the model:\\n\\n\")\n",
    "    drug_performance.write(top_mlp_classification_report)\n",
    "    \n",
    "\n",
    "#-------------Step 8: Redo step 6 10 times-------------#\n",
    "\n",
    "#--------(a) NB--------#\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n------------------------------------Step 8------------------------------------\")\n",
    "    drug_performance.write(\"\\n\\n1. Redo the Gaussian Naive Bayes Classifier 10 times\")\n",
    "\n",
    "        \n",
    "# To store all 10 predictions, accuracy, macro_f1 and weighted_f1\n",
    "array_nb_predictions = []\n",
    "array_nb_accuracy = []\n",
    "array_nb_macro_f1 = []\n",
    "array_nb_weighted_f1 = []\n",
    "\n",
    "\n",
    "# Iterating 10 times\n",
    "for i in range (10):\n",
    "    iteration_nbClf = GaussianNB()\n",
    "    iteration_nbClf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the outputs and calculating the accuracy, macro_f1 and weighted_f1. All values appended to their respective arrays.\n",
    "    array_nb_predictions.append(iteration_nbClf.predict(X_test))\n",
    "    array_nb_accuracy.append(accuracy_score(y_test, array_nb_predictions[i]))\n",
    "    array_nb_macro_f1.append(f1_score(y_test, array_nb_predictions[i], average = \"macro\"))\n",
    "    array_nb_weighted_f1.append(f1_score(y_test, array_nb_predictions[i], average = \"weighted\"))\n",
    "    \n",
    "    \"\"\"\n",
    "    # Appending the 10 predictions to a .txt file\n",
    "    with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "        drug_performance.write(\"\\n\\nIteration #\" + str(i) + \": \\n\")\n",
    "        drug_performance.write(np.array2string(array_nb_predictions[i]))\n",
    "    \"\"\"\n",
    "\n",
    "# Calculating the average accuracy, macro-average F1, weighted-average F1, standard devitation for the accuracy, standard devitation of the macro-average F1, standard devitation of the weighted-average F1  \n",
    "iteration_nb_avg_accuracy = statistics.mean(array_nb_accuracy)\n",
    "iteration_nb_macro_avg_f1 = statistics.mean(array_nb_macro_f1)\n",
    "iteration_nb_weighted_avg_f1 = statistics.mean(array_nb_weighted_f1)\n",
    "iteration_nb_std_accuracy = statistics.stdev(array_nb_accuracy)\n",
    "iteration_nb_std_macro_avg_f1 = statistics.stdev(array_nb_macro_f1)\n",
    "iteration_nb_std_weighted_avg_f1 = statistics.stdev(array_nb_weighted_f1)\n",
    "\n",
    "\n",
    "# Appending values to the .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\nAverage accuracy: \")\n",
    "    drug_performance.write(str(iteration_nb_avg_accuracy))\n",
    "\n",
    "    drug_performance.write(\"\\nMacro-average f1: \")\n",
    "    drug_performance.write(str(iteration_nb_macro_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\nWeighted-average f1: \")\n",
    "    drug_performance.write(str(iteration_nb_weighted_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\n\\nStandard deviation for the accuracy: \")\n",
    "    drug_performance.write(str(iteration_nb_std_accuracy))\n",
    "\n",
    "    drug_performance.write(\"\\nStandard deviation of the macro-average F1: \")\n",
    "    drug_performance.write(str(iteration_nb_std_macro_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\nStandard deviation of the macro-average F1: \")\n",
    "    drug_performance.write(str(iteration_nb_std_weighted_avg_f1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#--------(b) Base-DT--------#\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n****************************************************************\")\n",
    "    drug_performance.write(\"\\n\\n2. Redo the Decision Tree Classifier 10 times\")\n",
    "        \n",
    "\n",
    "# To store all 10 predictions, accuracy, macro_f1 and weighted_f1\n",
    "array_dtClf_predictions = []\n",
    "array_dtClf_accuracy = []\n",
    "array_dtClf_macro_f1 = []\n",
    "array_dtClf_weighted_f1 = []\n",
    "\n",
    "\n",
    "# Iterating 10 times\n",
    "for i in range (10):\n",
    "    iteration_dtClf = DecisionTreeClassifier()\n",
    "    iteration_dtClf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the outputs and calculating the accuracy, macro_f1 and weighted_f1. All values appended to their respective arrays.\n",
    "    array_dtClf_predictions.append(iteration_dtClf.predict(X_test))\n",
    "    array_dtClf_accuracy.append(accuracy_score(y_test, array_dtClf_predictions[i]))\n",
    "    array_dtClf_macro_f1.append(f1_score(y_test, array_dtClf_predictions[i], average = \"macro\"))\n",
    "    array_dtClf_weighted_f1.append(f1_score(y_test, array_dtClf_predictions[i], average = \"weighted\"))\n",
    "    \n",
    "    \"\"\"\n",
    "    # Appending the 10 predictions to a .txt file\n",
    "    with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "        drug_performance.write(\"\\n\\nIteration #\" + str(i) + \": \\n\")\n",
    "        drug_performance.write(np.array2string(array_dtClf_predictions[i]))\n",
    "    \"\"\"     \n",
    "\n",
    "    \n",
    "# Calculating the average accuracy, macro-average F1, weighted-average F1, standard devitation for the accuracy, standard devitation of the macro-average F1, standard devitation of the weighted-average F1   \n",
    "iteration_dtClf_avg_accuracy = statistics.mean(array_dtClf_accuracy)\n",
    "iteration_dtClf_macro_avg_f1 = statistics.mean(array_dtClf_macro_f1)\n",
    "iteration_dtClf_weighted_avg_f1 = statistics.mean(array_dtClf_weighted_f1)\n",
    "iteration_dtClf_std_accuracy = statistics.stdev(array_dtClf_accuracy)\n",
    "iteration_dtClf_std_macro_avg_f1 = statistics.stdev(array_dtClf_macro_f1)\n",
    "iteration_dtClf_std_weighted_avg_f1 = statistics.stdev(array_dtClf_weighted_f1)\n",
    "\n",
    "\n",
    "# Appending values to the .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\nAverage accuracy: \")\n",
    "    drug_performance.write(str(iteration_dtClf_avg_accuracy))\n",
    "\n",
    "    drug_performance.write(\"\\nMacro-average f1: \")\n",
    "    drug_performance.write(str(iteration_dtClf_macro_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\nWeighted-average f1: \")\n",
    "    drug_performance.write(str(iteration_dtClf_weighted_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\n\\nStandard deviation for the accuracy: \")\n",
    "    drug_performance.write(str(iteration_dtClf_std_accuracy))\n",
    "\n",
    "    drug_performance.write(\"\\nStandard deviation of the macro-average F1: \")\n",
    "    drug_performance.write(str(iteration_dtClf_std_macro_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\nStandard deviation of the macro-average F1: \")\n",
    "    drug_performance.write(str(iteration_dtClf_std_weighted_avg_f1))\n",
    "\n",
    "\n",
    "    \n",
    "#--------(c)Top_DT--------#\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n****************************************************************\")\n",
    "    drug_performance.write(\"\\n\\n3. Redo the Top Decision Tree 10 times\")\n",
    "        \n",
    "    \n",
    "# To store all 10 predictions, accuracy, macro_f1 and weighted_f1\n",
    "array_topDtClf_predictions = []\n",
    "array_topDtClf_accuracy = []\n",
    "array_topDtClf_macro_f1 = []\n",
    "array_topDtClf_weighted_f1 = []\n",
    "\n",
    "\n",
    "# Iterating 10 times\n",
    "for i in range (10):\n",
    "    iteration_topDtClf = GridSearchCV(DecisionTreeClassifier(), top_DT_param_grid)\n",
    "    iteration_topDtClf.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the outputs and calculating the accuracy, macro_f1 and weighted_f1. All values appended to their respective arrays.\n",
    "    array_topDtClf_predictions.append(iteration_topDtClf.predict(X_test))\n",
    "    array_topDtClf_accuracy.append(accuracy_score(y_test, array_topDtClf_predictions[i]))\n",
    "    array_topDtClf_macro_f1.append(f1_score(y_test, array_topDtClf_predictions[i], average = \"macro\"))\n",
    "    array_topDtClf_weighted_f1.append(f1_score(y_test, array_topDtClf_predictions[i], average = \"weighted\"))\n",
    "    \n",
    "    \"\"\"\n",
    "    # Appending the 10 predictions to a .txt file\n",
    "    with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "        drug_performance.write(\"\\n\\nIteration #\" + str(i) + \": \\n\")\n",
    "        drug_performance.write(np.array2string(array_topDtClf_predictions))\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "# Calculating the average accuracy, macro-average F1, weighted-average F1, standard devitation for the accuracy, standard devitation of the macro-average F1, standard devitation of the weighted-average F1   \n",
    "iteration_topDtClf_avg_accuracy = statistics.mean(array_topDtClf_accuracy)\n",
    "iteration_topDtClf_macro_avg_f1 = statistics.mean(array_topDtClf_macro_f1)\n",
    "iteration_topDtClf_weighted_avg_f1 = statistics.mean(array_topDtClf_weighted_f1)\n",
    "iteration_topDtClf_std_accuracy = statistics.stdev(array_topDtClf_accuracy)\n",
    "iteration_topDtClf_std_macro_avg_f1 = statistics.stdev(array_topDtClf_macro_f1)\n",
    "iteration_topDtClf_std_weighted_avg_f1 = statistics.stdev(array_topDtClf_weighted_f1)\n",
    "\n",
    "# Appending values to the .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\nAverage accuracy: \")\n",
    "    drug_performance.write(str(iteration_topDtClf_avg_accuracy))\n",
    "\n",
    "    drug_performance.write(\"\\nMacro-average f1: \")\n",
    "    drug_performance.write(str(iteration_topDtClf_macro_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\nWeighted-average f1: \")\n",
    "    drug_performance.write(str(iteration_topDtClf_weighted_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\n\\nStandard deviation for the accuracy: \")\n",
    "    drug_performance.write(str(iteration_topDtClf_std_accuracy))\n",
    "\n",
    "    drug_performance.write(\"\\nStandard deviation of the macro-average F1: \")\n",
    "    drug_performance.write(str(iteration_topDtClf_std_macro_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\nStandard deviation of the macro-average F1: \")\n",
    "    drug_performance.write(str(iteration_topDtClf_std_weighted_avg_f1))\n",
    "\n",
    "\n",
    "#--------(d)Perceptron--------#\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n****************************************************************\")\n",
    "    drug_performance.write(\"\\n\\n4. Redo the Perceptron 10 times\")\n",
    "\n",
    "    \n",
    "# To store all 10 predictions, accuracy, macro_f1 and weighted_f1\n",
    "array_perClf_predictions = []\n",
    "array_perClf_accuracy = []\n",
    "array_perClf_macro_f1 = []\n",
    "array_perClf_weighted_f1 = []\n",
    "\n",
    "\n",
    "# Iterating 10 times\n",
    "for i in range (10):\n",
    "    iteration_perClf = Perceptron()\n",
    "    iteration_perClf.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the outputs and calculating the accuracy, macro_f1 and weighted_f1. All values appended to their respective arrays.\n",
    "    array_perClf_predictions.append(iteration_perClf.predict(X_test))\n",
    "    array_perClf_accuracy.append(accuracy_score(y_test, array_perClf_predictions[i]))\n",
    "    array_perClf_macro_f1.append(f1_score(y_test, array_perClf_predictions[i], average = \"macro\"))\n",
    "    array_perClf_weighted_f1.append(f1_score(y_test, array_perClf_predictions[i], average = \"weighted\"))\n",
    "    \n",
    "    \"\"\"\n",
    "    # Appending the 10 predictions to a .txt file\n",
    "    with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "        drug_performance.write(\"\\n\\nIteration #\" + str(i) + \": \\n\")\n",
    "        drug_performance.write(np.array2string(array_perClf_predictions[i]))\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "# Calculating the average accuracy, macro-average F1, weighted-average F1, standard devitation for the accuracy, standard devitation of the macro-average F1, standard devitation of the weighted-average F1   \n",
    "iteration_perClf_avg_accuracy = statistics.mean(array_perClf_accuracy)\n",
    "iteration_perClf_macro_avg_f1 = statistics.mean(array_perClf_macro_f1)\n",
    "iteration_perClf_weighted_avg_f1 = statistics.mean(array_perClf_weighted_f1)\n",
    "iteration_perClf_std_accuracy = statistics.stdev(array_perClf_accuracy)\n",
    "iteration_perClf_std_macro_avg_f1 = statistics.stdev(array_perClf_macro_f1)\n",
    "iteration_perClf_std_weighted_avg_f1 = statistics.stdev(array_perClf_weighted_f1)\n",
    "\n",
    "# Appending values to the .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\nAverage accuracy: \")\n",
    "    drug_performance.write(str(iteration_perClf_avg_accuracy))\n",
    "\n",
    "    drug_performance.write(\"\\nMacro-average f1: \")\n",
    "    drug_performance.write(str(iteration_perClf_macro_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\nWeighted-average f1: \")\n",
    "    drug_performance.write(str(iteration_perClf_weighted_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\n\\nStandard deviation for the accuracy: \")\n",
    "    drug_performance.write(str(iteration_perClf_std_accuracy))\n",
    "\n",
    "    drug_performance.write(\"\\nStandard deviation of the macro-average F1: \")\n",
    "    drug_performance.write(str(iteration_perClf_std_macro_avg_f1))\n",
    "    \n",
    "    drug_performance.write(\"\\nStandard deviation of the macro-average F1: \")\n",
    "    drug_performance.write(str(iteration_perClf_std_weighted_avg_f1))\n",
    "\n",
    "    \n",
    "#--------(e)Base-MLP--------#\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n****************************************************************\")\n",
    "    drug_performance.write(\"\\n\\n5. Redo the Multi-Layered Perceptron Classifier 10 times\")\n",
    "\n",
    "    \n",
    "# To store all 10 predictions, accuracy, macro_f1 and weighted_f1\n",
    "array_mlpClf_predictions = []\n",
    "array_mlpClf_accuracy = []\n",
    "array_mlpClf_macro_f1 = []\n",
    "array_mlpClf_weighted_f1 = []\n",
    "\n",
    "# Iterating 10 times\n",
    "for i in range (10):\n",
    "    iteration_mlpClf = MLPClassifier(hidden_layer_sizes = (100, ), activation = 'logistic', solver = 'sgd')\n",
    "    iteration_mlpClf.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the outputs and calculating the accuracy, macro_f1 and weighted_f1. All values appended to their respective arrays.\n",
    "    array_mlpClf_predictions.append(iteration_mlpClf.predict(X_test))\n",
    "    array_mlpClf_accuracy.append(accuracy_score(y_test, array_mlpClf_predictions[i]))\n",
    "    array_mlpClf_macro_f1.append(f1_score(y_test, array_mlpClf_predictions[i], average = \"macro\"))\n",
    "    array_mlpClf_weighted_f1.append(f1_score(y_test, array_mlpClf_predictions[i], average = \"weighted\"))\n",
    "    \n",
    "    \"\"\"\n",
    "    # Appending the 10 predictions to a .txt file\n",
    "    with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "        drug_performance.write(\"\\n\\nIteration #\" + str(i) + \": \\n\")\n",
    "        drug_performance.write(np.array2string(array_mlpClf_predictions[i]))\n",
    "    \"\"\"\n",
    "        \n",
    "# Calculating the average accuracy, macro-average F1, weighted-average F1, standard devitation for the accuracy, standard devitation of the macro-average F1, standard devitation of the weighted-average F1   \n",
    "iteration_mlpClf_avg_accuracy = statistics.mean(array_mlpClf_accuracy)\n",
    "iteration_mlpClf_macro_avg_f1 = statistics.mean(array_mlpClf_macro_f1)\n",
    "iteration_mlpClf_weighted_avg_f1 = statistics.mean(array_mlpClf_weighted_f1)\n",
    "iteration_mlpClf_std_accuracy = statistics.stdev(array_mlpClf_accuracy)\n",
    "iteration_mlpClf_std_macro_avg_f1 = statistics.stdev(array_mlpClf_macro_f1)\n",
    "iteration_mlpClf_std_weighted_avg_f1 = statistics.stdev(array_mlpClf_weighted_f1)\n",
    "\n",
    "# Appending values to the .txt file\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\nAverage accuracy: \")\n",
    "    drug_performance.write(str(iteration_mlpClf_avg_accuracy))\n",
    "\n",
    "    drug_performance.write(\"\\nMacro-average f1: \")\n",
    "    drug_performance.write(str(iteration_mlpClf_macro_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\nWeighted-average f1: \")\n",
    "    drug_performance.write(str(iteration_mlpClf_weighted_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\n\\nStandard deviation for the accuracy: \")\n",
    "    drug_performance.write(str(iteration_mlpClf_std_accuracy))\n",
    "\n",
    "    drug_performance.write(\"\\nStandard deviation of the macro-average F1: \")\n",
    "    drug_performance.write(str(iteration_mlpClf_std_macro_avg_f1))\n",
    "    \n",
    "    drug_performance.write(\"\\nStandard deviation of the macro-average F1: \")\n",
    "    drug_performance.write(str(iteration_mlpClf_std_weighted_avg_f1))\n",
    "    \n",
    "    \n",
    "#--------(f)Top-MLP--------#\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\n****************************************************************\")\n",
    "    drug_performance.write(\"\\n\\n6. Redo the Top Multi-Layered Perceptron Classifier 10 times\")\n",
    "\n",
    "    \n",
    "# To store all 10 predictions, accuracy, macro_f1 and weighted_f1\n",
    "array_topMlpClf_predictions = []\n",
    "array_topMlpClf_accuracy = []\n",
    "array_topMlpClf_macro_f1 = []\n",
    "array_topMlpClf_weighted_f1 = []\n",
    "\n",
    "\n",
    "# Iterating 10 times\n",
    "for i in range (10):\n",
    "    iteration_topMlpClf = GridSearchCV(MLPClassifier(), top_MLP_param_grid)\n",
    "    iteration_topMlpClf.fit(X_train, y_train) # Fit the model for grid search\n",
    "\n",
    "    # Predicting the outputs and calculating the accuracy, macro_f1 and weighted_f1. All values appended to their respective arrays.\n",
    "    array_topMlpClf_predictions.append(iteration_topMlpClf.predict(X_test))\n",
    "    array_topMlpClf_accuracy.append(accuracy_score(y_test, array_topMlpClf_predictions[i]))\n",
    "    array_topMlpClf_macro_f1.append(f1_score(y_test, array_topMlpClf_predictions[i], average = \"macro\"))\n",
    "    array_topMlpClf_weighted_f1.append(f1_score(y_test, array_topMlpClf_predictions[i], average = \"weighted\"))\n",
    "    \n",
    "    \"\"\" \n",
    "    # Appending the 10 predictions to a .txt file\n",
    "    with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "        drug_performance.write(\"\\n\\nIteration #\" + str(i) + \": \\n\")\n",
    "        drug_performance.write(np.array2string(iteration_topMlpClf_predictions))\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "# Calculating the average accuracy, macro-average F1, weighted-average F1, standard devitation for the accuracy, standard devitation of the macro-average F1, standard devitation of the weighted-average F1   \n",
    "iteration_topMlpClf_avg_accuracy = statistics.mean(array_topMlpClf_accuracy)\n",
    "iteration_topMlpClf_macro_avg_f1 = statistics.mean(array_topMlpClf_macro_f1)\n",
    "iteration_topMlpClf_weighted_avg_f1 = statistics.mean(array_topMlpClf_weighted_f1)\n",
    "iteration_topMlpClf_std_accuracy = statistics.stdev(array_topMlpClf_accuracy)\n",
    "iteration_topMlpClf_std_macro_avg_f1 = statistics.stdev(array_topMlpClf_macro_f1)\n",
    "iteration_topMlpClf_std_weighted_avg_f1 = statistics.stdev(array_topMlpClf_weighted_f1)\n",
    "\n",
    "\n",
    "with open(\"drugs-performance.txt\", \"a\") as drug_performance:\n",
    "    drug_performance.write(\"\\n\\nAverage accuracy: \")\n",
    "    drug_performance.write(str(iteration_topMlpClf_avg_accuracy))\n",
    "\n",
    "    drug_performance.write(\"\\nMacro-average f1: \")\n",
    "    drug_performance.write(str(iteration_topMlpClf_macro_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\nWeighted-average f1: \")\n",
    "    drug_performance.write(str(iteration_topMlpClf_weighted_avg_f1))\n",
    "\n",
    "    drug_performance.write(\"\\n\\nStandard deviation for the accuracy: \")\n",
    "    drug_performance.write(str(iteration_topMlpClf_std_accuracy))\n",
    "\n",
    "    drug_performance.write(\"\\nStandard deviation of the macro-average F1: \")\n",
    "    drug_performance.write(str(iteration_topMlpClf_std_macro_avg_f1))\n",
    "    \n",
    "    drug_performance.write(\"\\nStandard deviation of the macro-average F1: \")\n",
    "    drug_performance.write(str(iteration_topMlpClf_std_weighted_avg_f1))\n",
    "    \n",
    "\n",
    "#-------------Step 8: Redo step 6 10 times-------------#\n",
    "\n",
    "with open(\"drugs-discussion.txt\", \"a\") as drugs_discussion:\n",
    "    drugs_discussion.write(\"For the NB, Base-DT, Top-DT and PER classifiers, the same model gives the same performance every time.\")\n",
    "    drugs_discussion.write(\"For the NB classifier, we are reusing the same splitted data (ie. the training data is always the same and the testing data as well). Since we are using the same training data for the 10 iterations to perform training, we will always get the same results when computing the prior and conditional probabilities. Thus, we will always get the same results during testing. This is the reason the performance stays the same throughout the 10 iterations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "717035e0-28f1-47ac-bf63-7efd0737d95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb1a4cc-866b-4ed7-b0b3-6f44fbfd8f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
