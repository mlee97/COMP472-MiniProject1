------------------------------------Step 7------------------------------------

(a)
Model name: Gaussian Naive Bayes Classifier

(b) Confusion matrix:

[[1 0 0 0 2]
 [0 1 0 0 1]
 [0 1 2 3 0]
 [2 0 4 5 4]
 [2 2 4 8 8]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       0.40      1.00      0.57         2
       drugB       1.00      0.57      0.73         7
       drugC       0.70      1.00      0.82         7
       drugX       1.00      1.00      1.00        16
       drugY       1.00      0.83      0.91        18

    accuracy                           0.88        50
   macro avg       0.82      0.88      0.81        50
weighted avg       0.93      0.88      0.89        50


****************************************************************

(a)
Model name: Decision Tree

(b) Confusion matrix:

[[ 0  1  0  0  2]
 [ 0  1  0  0  1]
 [ 0  1  1  3  1]
 [ 2  0  4  5  4]
 [ 0  4  2  7 11]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       1.00      1.00      1.00         2
       drugB       1.00      1.00      1.00         7
       drugC       1.00      1.00      1.00         7
       drugX       1.00      0.94      0.97        16
       drugY       0.95      1.00      0.97        18

    accuracy                           0.98        50
   macro avg       0.99      0.99      0.99        50
weighted avg       0.98      0.98      0.98        50


****************************************************************

(a)
Model name: A better performing Decision Tree

Changed hyper-parameters values: 
- criterion (gini or entropy)
- max_depth (3, 5)
- min_samples_split (2, 6, 10)

Best hyper-parameters:{'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2}

(b) Confusion matrix:

[[ 0  1  0  0  2]
 [ 0  1  0  0  1]
 [ 0  1  1  3  1]
 [ 2  0  4  5  4]
 [ 0  4  2  7 11]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       1.00      1.00      1.00         2
       drugB       1.00      1.00      1.00         7
       drugC       1.00      1.00      1.00         7
       drugX       1.00      0.94      0.97        16
       drugY       0.95      1.00      0.97        18

    accuracy                           0.98        50
   macro avg       0.99      0.99      0.99        50
weighted avg       0.98      0.98      0.98        50


****************************************************************

(a)
Model name: Perceptron

(b) Confusion matrix:

[[ 0  0  2  0  1]
 [ 0  0  1  0  1]
 [ 0  0  6  0  0]
 [ 0  0 13  0  2]
 [ 0  0 18  0  6]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       0.00      0.00      0.00         2
       drugB       0.00      0.00      0.00         7
       drugC       0.17      1.00      0.30         7
       drugX       0.00      0.00      0.00        16
       drugY       1.00      0.56      0.71        18

    accuracy                           0.34        50
   macro avg       0.24      0.31      0.20        50
weighted avg       0.38      0.34      0.30        50


****************************************************************

(a)
Model name: Multi-Layered Perceptron

(b) Confusion matrix:

[[ 0  0  0  1  2]
 [ 0  0  0  1  1]
 [ 0  0  0  3  3]
 [ 0  0  0  5 10]
 [ 0  0  0 11 13]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       0.00      0.00      0.00         2
       drugB       0.00      0.00      0.00         7
       drugC       0.00      0.00      0.00         7
       drugX       0.48      0.62      0.54        16
       drugY       0.59      0.94      0.72        18

    accuracy                           0.54        50
   macro avg       0.21      0.31      0.25        50
weighted avg       0.36      0.54      0.43        50


****************************************************************

(a)
Model name: A better performing Multi-Layered Perceptron

Changed hyper-parameters values: 
- activation function (sigmoid, tanh, relu and identity)
- 2 network architectures(2 hidden layers with 30+50 nodes and 3 hidden layers with 10 + 10 + 10)
- solver (Adam and stochastic gradient descent)

Best hyper-parameters:{'activation': 'tanh', 'hidden_layer_sizes': [30, 50], 'solver': 'adam'}

(b) Confusion matrix:

[[ 0  0  0  1  2]
 [ 0  0  0  1  1]
 [ 0  0  0  3  3]
 [ 0  0  0  5 10]
 [ 0  0  0 11 13]]

(c) Precision, recall, and F1-measure for each class AND 
(d) Accuracy, macro-average F1 and weighted-average F1 of the model:

              precision    recall  f1-score   support

       drugA       0.00      0.00      0.00         2
       drugB       0.00      0.00      0.00         7
       drugC       0.00      0.00      0.00         7
       drugX       0.48      0.62      0.54        16
       drugY       0.59      0.94      0.72        18

    accuracy                           0.54        50
   macro avg       0.21      0.31      0.25        50
weighted avg       0.36      0.54      0.43        50


------------------------------------Step 8------------------------------------

1. Redo the Gaussian Naive Bayes Classifier 10 times

Average accuracy: 0.88
Macro-average f1: 0.8062643239113827
Weighted-average f1: 0.8872421695951107

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the weighted-average F1: 0.0

****************************************************************

2. Redo the Decision Tree Classifier 10 times

Average accuracy: 0.98
Macro-average f1: 0.9881429816913687
Weighted-average f1: 0.979947689625109

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the weighted-average F1: 0.0

****************************************************************

3. Redo the Top Decision Tree 10 times

Average accuracy: 0.98
Macro-average f1: 0.9881429816913687
Weighted-average f1: 0.979947689625109

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the weighted-average F1: 0.0

****************************************************************

4. Redo the Perceptron 10 times

Average accuracy: 0.34
Macro-average f1: 0.2024316109422492
Weighted-average f1: 0.2988449848024316

Standard deviation for the accuracy: 0.0
Standard deviation of the macro-average F1: 0.0
Standard deviation of the weighted-average F1: 0.0

****************************************************************

5. Redo the Multi-Layered Perceptron Classifier 10 times

Average accuracy: 0.514
Macro-average f1: 0.23819386190358835
Weighted-average f1: 0.40927250355001116

Standard deviation for the accuracy: 0.013498971154211071
Standard deviation of the macro-average F1: 0.007664239354852198
Standard deviation of the weighted-average F1: 0.012658248599924317

****************************************************************

6. Redo the Top Multi-Layered Perceptron Classifier 10 times

Average accuracy: 0.74
Macro-average f1: 0.5942836926435457
Weighted-average f1: 0.6791930357688007

Standard deviation for the accuracy: 0.06182412330330467
Standard deviation of the macro-average F1: 0.10052953121401562
Standard deviation of the weighted-average F1: 0.07235504381595485